# GenAI Risk Assessment Tool (v0.1)

This repository documents my early-stage work in **GRC and AI risk engineering**, using Python to explore security risks outlined in the **OWASP GenAI Security Project**.

The focus is not just on identifying risks, but on **translating GenAI behavior into governance, risk, and control logic**.

---

## Purpose

* Practice Python fundamentals in a GenAI security context
* Study how GenAI systems can fail, be misused, or leak data
* Convert security concepts into **structured, testable risk logic**
* Build intuition for **AI risk assessment beyond checklists**

---

## What This Project Does

* Stores GenAI risks using Python lists and dictionaries
* Evaluates risks using simple conditional logic
* Simulates agentic behavior and trust assumptions
* Maps technical behaviors to **risk, impact, and mitigation thinking**

This project is intentionally simple at this stage, prioritizing **clarity of reasoning over complexity**.

---

## Learning Focus (Current)

* Python fundamentals (data structures, control flow, functions)
* OWASP GenAI risks (e.g., Prompt Injection, Data Leakage, Model Misuse)
* Early agentic risk modeling
* Logging security-relevant outcomes programmatically

---

## Status

This is an **early learning version (v0.1)**.

The project will evolve as I deepen my understanding of:

* OWASP GenAI threats and mitigations
* Secure-by-design AI systems
* GRC engineering workflows

The goal is steady progression from **learning artifacts → job-ready security tooling**.



Keep going. You’re building the right way.
